Why Self-Attention is Needed in Transformers

1.The Problem with Old Models (RNNs / LSTMs)

RNNs and LSTMs process sentences sequentially — word by word. They read input in order (left to right), and each step depends on the previous one. This creates several problems:
A. They are slow
Because each step must wait for the previous one, the model cannot run in parallel. This makes training and inference slow.
B. They forget long-range relationships
Even LSTMs, which include mechanisms to handle long-term memory, struggle to remember information that appeared many words earlier. The influence of earlier words fades as sentences get longer.
C. They suffer from a bottleneck
At each step, the model must compress all previous context into a single hidden state vector. This bottleneck makes it difficult to store detailed or long-range information.

How Transformers Solve These Problems

Transformers introduce a new mechanism called Self-Attention, which removes recurrence entirely.
A. Parallel processing
Transformers process all words at once instead of step-by-step. This allows massive parallelization and greatly improves speed.
B. Self-Attention captures relationships between any words
Every word can directly connect to every other word, regardless of distance. This allows the model to understand long-range dependencies naturally and without information loss.
C. Positional encoding replaces recurrence
Since Transformers do not read words in order, they add positional encodings to each word embedding. This provides the model with information about the order of words in the sentence.


2.What Self-Attention Does

Self-Attention allows every word to look at all other words in the sentence and decide:
“Which words are most relevant for understanding my meaning?”
It lets the model pick out helpful context automatically.

Example:
Sentence: “Apple launched a new phone”

When processing the word “Apple”, the model must decide if it refers to a fruit or a company.
The word “phone” provides strong context, so “Apple” pays more attention to it.
This helps the model understand that “Apple” refers to the company, not the fruit.

Self-Attention basically allows words to use each other as clues, no matter how far apart they are.

3. Working of Self-Attention :

STATIC vs CONTEXTUAL EMBEDDINGS

What Are Static Embeddings?
Examples: Word2Vec, GloVe, FastText
Each word has one fixed vector.
“Bank” (financial) and “bank” (river bank) → same embedding.
“Apple” (fruit) and “Apple” (company) → same vector.
No sentence awareness.

money  → e_money
bank   → e_bank
grows  → e_grows
These embeddings never change regardless of the sentence.

Why Static Embeddings Are Not Enough

Word meanings depend on context:
“bank” in money bank grows
“bank” in river bank flows
Static embedding cannot tell the difference

Enter Self-Attention → Contextual Embeddings

Self-Attention transforms each embedding based on how strongly it relates to other words in the same sentence.
The formula is:
                ei(new)​=(1toj)∑​wij​⋅ej​

w_ij = attention weight from word i to word j
e_j = embedding of word j
This turns fixed vectors → context-aware vectors.

Sentence 1
money attends → 0.7 money + 0.2 bank + 0.1 grows
bank  attends → 0.25 money + 0.7 bank + 0.05 grows
grows attends → 0.1 money + 0.2 bank + 0.7 grows

Contextual Embeddings (Sentence 1)
y_money = 0.7*e_money + 0.2*e_bank + 0.1*e_grows
y_bank  = 0.25*e_money + 0.7*e_bank + 0.05*e_grows
y_grows = 0.1*e_money + 0.2*e_bank + 0.7*e_grows

Sentence 2 

river attends → 0.8 river + 0.15 bank + 0.05 flows
bank  attends → 0.2 river + 0.78 bank + 0.02 flows
flows attends → 0.4 river + 0.01 bank + 0.59 flows

Contextual Embeddings (Sentence 2)
y_river = 0.8*e_river + 0.15*e_bank + 0.05*e_flows
y_bank  = 0.2*e_river + 0.78*e_bank + 0.02*e_flows
y_flows = 0.4*e_river + 0.01*e_bank + 0.59*e_flows

Contextual embeddings solve the biggest linguistic problem:
One word = multiple meanings.
Transformers generate embeddings that depend on the entire sentence, not just the word itself.

Static embedding = dictionary meaning
Contextual embedding = meaning in the sentence (through Self-Attention)


Self-Attention answers one key question:
“When understanding this word, which other words should I pay attention to, and by how much?”

It solves:
✅ Long-range dependency
✅ Multiple meanings (polysemy)
✅ Parallel computation (no recurrence)
✅ Context-aware representations


4. Introducing Q, K, V (Query, Key, Value)

Until now, we saw what Self-Attention does:
It lets each word look at all other words and decide how much to use them to understand its meaning.

But how does a word decide which other words are useful?
To make this decision, Transformers give three different versions of each word:

1) Query (Q) — What the word is looking for

This is like the word asking a question:
“Who can help me understand myself?”
“What clues do I need?”

Example:
If the word is Apple, its Query represents:
“Help me decide if I'm a fruit or the company.”

2) Key (K) — What each word offers

Every word also carries a “tag” that represents what kind of information it contains.

Examples:
“phone” offers tech-related meaning
“tree” offers nature-related meaning
“money” offers financial meaning
“river” offers water/environment meaning
Keys tell other words:
“This is what I represent.”

3) Value (V) — The actual information each word provides

If a word is selected as important, its Value holds the information that gets added into the contextual meaning.
Think of Value as:
“If you choose me, here is the meaning I will contribute.”

Putting Q, K, V Together (A Simple Story)

Imagine we want to understand the meaning of the word bank.

Step 1 — “bank” creates a Query
Its Query asks:
“Am I a financial bank or a river bank? What clues do I need?”

Step 2 — All other words offer their Keys
“money” offers: “I'm related to finance.”
“river” offers: “I'm related to nature/water.”
“flows” offers: “I'm related to movement in water.”

Step 3 — The Query of “bank” matches each Key

Q(bank) matches strongly with K(money) → financial context
Q(bank) matches weakly with K(grows) → not helpful
Q(bank) matches strongly with K(river) → water context

Step 4 — Only the useful words contribute their Values

If bank attends more to “money”, its Value vector becomes financial
If it attends more to “river”, its Value vector becomes nature-related

This is how:

“bank” → finance meaning in one sentence
“bank” → river meaning in another sentence

Q, K, V allow Self-Attention to determine meaning based on context.

Why Q, K, V Are Needed

Before this step, every word had only one embedding vector.
But each word has three roles inside attention:

It must ask things → Query
It must represent itself → Key
It must provide meaning → Value

So the Transformer creates Q, K, V by applying three learnable transformations to the original word embedding.

This allows the model to learn:
What questions a word should ask (Q)
What information a word carries (K)
What meaning a word provides when selected (V)


5. How Attention Scores Are Calculated (Q, K → Weights → V)

Once every word has its Query (Q), Key (K), and Value (V), Self-Attention must determine which words matter for understanding the meaning of the current word.
This happens in three clear steps.

Q = E × W_Q
K = E × W_K
V = E × W_V

These matrices are trained along with the whole Transformer.

5.1 Step 1 — Similarity (Q compared with K)

To understand a specific word (say “river”), the model compares:
Q_river → what “river” is looking for
with
K_river, K_bank, K_flows → what each word offers

This comparison produces raw similarity scores, which answer:
“How relevant is each word to ‘river’?”

sim(river, river)
sim(river, bank)
sim(river, flows)

5.2 Step 2 — Softmax (Scores → Attention Weights)

Raw scores can be:
negative
very large
unbounded

Softmax converts these into normalized weights:
positive values
sum to 1
represent “how much attention each word deserves”

w_river,river = 0.80
w_river,bank  = 0.15
w_river,flows = 0.05

These weights come directly from the Q–K similarity.

5.3 Step 3 — Weighted Sum (THIS IS WHERE V IS USED)

Once attention weights are known, the model gathers information from the other words.
This information is taken from each word’s Value vector (V).

Each Value vector is computed as:
V_word = E_word × W_V

y_river = 0.80 * V_river
        + 0.15 * V_bank
        + 0.05 * V_flows

This is the moment where:
Q asked the question
K decided relevance
V provided the actual meaning

